{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1HF5JajkTaQDzJ4wIjBcedyftRxE5gPMb",
      "authorship_tag": "ABX9TyP93qYqPrsy2jkqzaRVKBtr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larissa-rangel/IA376/blob/main/esse_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VAE model for EEG Data Augmentation\n",
        "\n",
        "link: https://github.com/arkanivasarkar/EEG-Data-Augmentation-using-Variational-Autoencoder\n",
        "\n",
        "Paper: https://arxiv.org/pdf/1611.08024.pdf\n",
        "\n",
        "\n",
        "Referências:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/keras/save_and_load?hl=pt-br"
      ],
      "metadata": {
        "id": "vNS3T0yXTsQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading libraries"
      ],
      "metadata": {
        "id": "7DENys3jZNGQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6exzs4gOtSH",
        "outputId": "863b8569-19b1-4774-ae2d-7621346f8470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.23.5)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56439 sha256=0e50be60bc83f4473cf09729e7816ff6b989b123c62c7afb18ca2f10b597fee6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dp4sLEV0OMux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc70f5d1-74c5-4d60-ab12-8aff89a93078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting braindecode==0.7\n",
            "  Downloading Braindecode-0.7-py3-none-any.whl (184 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/184.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m184.3/184.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne (from braindecode==0.7)\n",
            "  Downloading mne-1.5.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (1.11.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from braindecode==0.7) (3.9.0)\n",
            "Collecting skorch (from braindecode==0.7)\n",
            "  Downloading skorch-0.15.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.3/239.3 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode==0.7) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode==0.7) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->braindecode==0.7) (2023.3.post1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch->braindecode==0.7) (1.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch->braindecode==0.7) (0.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->braindecode==0.7) (4.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->braindecode==0.7) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->braindecode==0.7) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch->braindecode==0.7) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch->braindecode==0.7) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne->braindecode==0.7) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.7) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.7) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.7) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode==0.7) (2023.7.22)\n",
            "Installing collected packages: skorch, mne, braindecode\n",
            "Successfully installed braindecode-0.7 mne-1.5.1 skorch-0.15.0\n",
            "Collecting moabb\n",
            "  Downloading moabb-1.0.0-py3-none-any.whl (563 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.8/563.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from moabb) (6.0.1)\n",
            "Collecting coverage<8.0.0,>=7.0.1 (from moabb)\n",
            "  Downloading coverage-7.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting edflib-python<2.0.0,>=1.0.6 (from moabb)\n",
            "  Downloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\n",
            "Collecting h5py<=3.8.0 (from moabb)\n",
            "  Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4.0.0,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from moabb) (3.7.1)\n",
            "Collecting memory-profiler<0.62.0,>=0.61.0 (from moabb)\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: mne<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.5.1)\n",
            "Collecting mne-bids<0.14,>=0.13 (from moabb)\n",
            "  Downloading mne_bids-0.13-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.22 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.23.5)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.5.3)\n",
            "Requirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.8.0)\n",
            "Collecting pyriemann<0.6,>=0.5 (from moabb)\n",
            "  Downloading pyriemann-0.5.tar.gz (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytest<8.0.0,>=7.4.0 in /usr/local/lib/python3.10/dist-packages (from moabb) (7.4.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.10/dist-packages (from moabb) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from moabb) (1.11.3)\n",
            "Requirement already satisfied: seaborn<0.13.0,>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from moabb) (0.12.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from moabb) (4.66.1)\n",
            "Collecting urllib3<2.0.0,>=1.26.15 (from moabb)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (2.8.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler<0.62.0,>=0.61.0->moabb) (5.9.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne<2.0,>=1.4->moabb) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne<2.0,>=1.4->moabb) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.2->moabb) (2023.3.post1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch<2.0.0,>=1.6.0->moabb) (4.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyriemann<0.6,>=0.5->moabb) (1.3.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.0->moabb) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.6.2->moabb) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne<2.0,>=1.4->moabb) (2.1.3)\n",
            "Building wheels for collected packages: pyriemann\n",
            "  Building wheel for pyriemann (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyriemann: filename=pyriemann-0.5-py2.py3-none-any.whl size=107752 sha256=1b3030225cd6c14213531e56756c25b0b4f9edc355f2cd5948d8d1ebe9d3eb56\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/86/79/622e9c1dc933dc088e287ebfaac5aa9bdc6a38a9db193ce1f1\n",
            "Successfully built pyriemann\n",
            "Installing collected packages: urllib3, memory-profiler, h5py, edflib-python, coverage, pyriemann, mne-bids, moabb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "Successfully installed coverage-7.3.2 edflib-python-1.0.8 h5py-3.8.0 memory-profiler-0.61.0 mne-bids-0.13 moabb-1.0.0 pyriemann-0.5 urllib3-1.26.18\n"
          ]
        }
      ],
      "source": [
        "!pip install braindecode==0.7\n",
        "!pip install moabb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn\n",
        "import umap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cunUQKU6qt0",
        "outputId": "a13bda37-83e8-4189-99d0-c8fb90b93b8b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86831 sha256=7495a31167069c09b64fabb92cbad98194e0ae85477cf7102b367d7beeb459fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=6958aa61b45de0f58eea26cad05bb517f7b2c34099c8b42473643fbc1440fe13\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.10 umap-learn-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h2_9NgpdOPHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aaec5e8-e2b5-48d5-f6ae-c5a5cb2233d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0) # Set for our testing purposes, please do not change!\n",
        "\n",
        "from braindecode.datasets import MOABBDataset\n",
        "from braindecode.preprocessing import (\n",
        "    exponential_moving_standardize, preprocess, Preprocessor)\n",
        "from braindecode.preprocessing import \\\n",
        "    create_windows_from_events, create_fixed_length_windows\n",
        "from sklearn.preprocessing import scale as standard_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2N7BshTkTrdK"
      },
      "outputs": [],
      "source": [
        "#bibliotecas para carregar o dataset e para arquitetura da rede\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Dense, Lambda, Reshape, Flatten, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bibliotecas para visualização do espaço latente\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "vu5Yc7k8hEj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kux7rdXClzfr"
      },
      "source": [
        "## Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aMuPSk7KORh5"
      },
      "outputs": [],
      "source": [
        "def preprocessor(\n",
        "    dataset,\n",
        "    low_cut_hz = 4.,   # low cut frequency for filtering\n",
        "    high_cut_hz = 38., # high cut frequency for filtering\n",
        "    newfreq = 100, # Paramater for resampling\n",
        "    factor = 1e6, # Parameter for scaling\n",
        "    ):\n",
        "\n",
        "    preprocessors = [\n",
        "        Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
        "#         Preprocessor(lambda data: np.multiply(data, factor)),  # Convert from V to uV\n",
        "        Preprocessor(\"resample\", sfreq=newfreq), # Resampling\n",
        "        Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
        "        Preprocessor(\"set_eeg_reference\", ref_channels=\"average\", ch_type=\"eeg\"), # Common Average Reference\n",
        "        Preprocessor(standard_scale, channel_wise=True) ## Standard Scale window\n",
        "    ]\n",
        "\n",
        "    # Transform the data\n",
        "    # return preprocess(dataset, preprocessors, n_jobs = -1)\n",
        "    return preprocess(dataset, preprocessors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tTJ5ZyPDOSay"
      },
      "outputs": [],
      "source": [
        "def get_windows(\n",
        "        dataset,\n",
        "        trial_start_offset_samples=0,\n",
        "        trial_stop_offset_samples=100,\n",
        "        window_size_samples=400,\n",
        "        window_stride_samples=100,\n",
        "        preload=True,\n",
        "        # mapping = {'left_hand': 0, 'right_hand': 1},\n",
        "        picks = ['C3', 'Cz', 'C4']\n",
        "        ):\n",
        "\n",
        "    windows_dataset = create_windows_from_events(\n",
        "        dataset,\n",
        "        trial_start_offset_samples = trial_start_offset_samples,\n",
        "        trial_stop_offset_samples  = trial_stop_offset_samples,\n",
        "        window_size_samples        = window_size_samples,\n",
        "        window_stride_samples      = window_stride_samples,\n",
        "        preload                    = True,\n",
        "        # mapping = {'left_hand': 0, 'right_hand': 1},\n",
        "        #picks                      = picks\n",
        "        )\n",
        "\n",
        "    # preprocess(windows_dataset, [Preprocessor(standard_scale, channel_wise=True)]) ## Standard Scale window\n",
        "\n",
        "    return windows_dataset\n",
        "\n",
        "\n",
        "def get_tensors_from_windows(windows_dataset):\n",
        "    windows_list = []\n",
        "    labels_list = []\n",
        "    n_runs = len(windows_dataset.datasets)\n",
        "    for i in range(n_runs):\n",
        "        windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
        "        labels_list.append(windows_dataset.datasets[i].y)\n",
        "\n",
        "    stacked_tensor = np.concatenate(windows_list, axis=0)\n",
        "    stacked_labels = np.concatenate(labels_list, axis=0)\n",
        "\n",
        "    del windows_list,labels_list\n",
        "\n",
        "    return stacked_tensor, stacked_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Khk7czwQOUKI"
      },
      "outputs": [],
      "source": [
        "class EEG(Dataset):\n",
        "\n",
        "    def __init__(self, subject_id = 3, dataset_name=\"BNCI2014_001\", transform = None):\n",
        "\n",
        "        self.raw_dataset     = MOABBDataset(dataset_name = dataset_name, subject_ids=subject_id)\n",
        "        self.prepro_dataset  = preprocessor(self.raw_dataset)\n",
        "        self.windows_dataset = get_windows(self.prepro_dataset)\n",
        "        self.data            = get_tensors_from_windows(self.windows_dataset)\n",
        "        self.transform       = transform\n",
        "        self.classes         = self.windows_dataset.datasets[0].windows.event_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data[0].shape[0]\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        # sample = {'signal': torch.from_numpy(self.data[0])[idx], 'label': torch.from_numpy(self.data[1])[idx]}\n",
        "\n",
        "        sample = (torch.from_numpy(np.expand_dims(self.data[0], axis = 1))[idx], torch.from_numpy(self.data[1])[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cSlLVHEpOWRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ccf2b8-5184-46fd-d766-e4ff93988554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/moabb/datasets/download.py:55: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BNCI_PATH\"\n",
            "  set_config(key, get_config(\"MNE_DATA\"))\n",
            "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat' to file '/root/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03T.mat'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNE_DATA is not already configured. It will be set to default location in the home directory - /root/mne_data\n",
            "All datasets will be downloaded to this location, if anything is already downloaded, please move manually to this location\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
            "  warnings.warn(\n",
            "100%|█████████████████████████████████████| 44.1M/44.1M [00:00<00:00, 7.42GB/s]\n",
            "SHA256 hash of downloaded file: 7e731ee8b681d5da6ecb11ae1d4e64b1653c7f15aad5d6b7620b25ce53141e80\n",
            "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
            "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat' to file '/root/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03E.mat'.\n",
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
            "  warnings.warn(\n",
            "100%|█████████████████████████████████████| 42.3M/42.3M [00:00<00:00, 11.4GB/s]\n",
            "SHA256 hash of downloaded file: d4229267ec7624fa8bd3af5cbebac17f415f7c722de6cb676748f8cb3b717d97\n",
            "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 165 samples (1.650 s)\n",
            "\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
          ]
        }
      ],
      "source": [
        "my_eeg_data = EEG(subject_id=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LqFlNRrgOZgZ"
      },
      "outputs": [],
      "source": [
        "x = my_eeg_data[:][0].detach().numpy()\n",
        "eletrodos = x.shape[2]\n",
        "amostras  = x.shape[3]\n",
        "y = my_eeg_data[:][1].detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LvMYCDnWlzfr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_val = tf.reduce_min(X_train)\n",
        "max_val = tf.reduce_max(X_train)\n",
        "\n",
        "X_train = (X_train - min_val) / (max_val - min_val) #Normalizando os dados\n",
        "X_test = (X_test - min_val) / (max_val - min_val)\n",
        "\n",
        "X_train = tf.cast(X_train, tf.float32) #Lança um tensor para um novo tipo.\n",
        "X_test = tf.cast(X_test, tf.float32)"
      ],
      "metadata": {
        "id": "2yg0X8gA2OS4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##VAE"
      ],
      "metadata": {
        "id": "DyvPTrY5ZHSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE model\n",
        "input_shape=(X_train.shape[1:])\n",
        "batch_size = 32\n",
        "kernel_size = 5\n",
        "filters = 16\n",
        "latent_dim = 2\n",
        "epochs = 1000\n",
        "\n",
        "# reparameterization\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# encoder\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "\n",
        "filters = filters* 2\n",
        "x = Conv2D(filters=filters,kernel_size=(1, 50),strides=(1,25),padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\n",
        "filters = filters* 2\n",
        "x = Conv2D(filters=filters,kernel_size=(eletrodos, 1),padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "shape = K.int_shape(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "z_log_var = z_log_var + 1e-8\n",
        "\n",
        "# reparameterization\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfyuCzumYZSy",
        "outputId": "f09f1144-ddba-4c7d-b9a7-cb4f2bd90da6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 1, 22, 400)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 1, 1, 32)             640032    ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 1, 1, 32)             128       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)     (None, 1, 1, 32)             0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 1, 1, 64)             45120     ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 1, 1, 64)             256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 1, 1, 64)             0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 64)                   0         ['leaky_re_lu_1[0][0]']       \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 16)                   1040      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 2)                    34        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 2)                    34        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.add (TFOpLambda)    (None, 2)                    0         ['z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            " z (Lambda)                  (None, 2)                    0         ['z_mean[0][0]',              \n",
            "                                                                     'tf.math.add[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 686644 (2.62 MB)\n",
            "Trainable params: 686452 (2.62 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "x = Conv2DTranspose(filters=filters,kernel_size=(eletrodos, 1),activation='relu',)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "filters = filters// 2\n",
        "x = Conv2DTranspose(filters=filters,kernel_size=(1, 400),activation='relu',strides=(1,25))(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "filters = filters// 2\n",
        "outputs = Conv2DTranspose(filters=1,kernel_size=kernel_size,padding='same',name='decoder_output')(x)\n",
        "outputs = Reshape((1,eletrodos,400))(outputs)\n",
        "\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIxwpjEuYakR",
        "outputId": "a965de81-c925-4346-dfda-7b37f7593f58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " z_sampling (InputLayer)     [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                192       \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 1, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 22, 1, 64)         90176     \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 22, 1, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 22, 400, 32)       819232    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 22, 400, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " decoder_output (Conv2DTran  (None, 22, 400, 1)        801       \n",
            " spose)                                                          \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 1, 22, 400)        0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 910785 (3.47 MB)\n",
            "Trainable params: 910593 (3.47 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE model (merging encoder and decoder)\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = Model(inputs, outputs, name='vae')\n",
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWQ90acMYeWI",
        "outputId": "0a877139-a6e8-4748-a1cc-b6d4855464ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 1, 22, 400)]      0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               686644    \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 1, 22, 400)        910785    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1597429 (6.09 MB)\n",
            "Trainable params: 1597045 (6.09 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer\n",
        "optimizer = Adam(learning_rate=0.001, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "# compiling vae\n",
        "vae.compile(optimizer=optimizer, loss= 'mse', metrics = 'accuracy')\n",
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LkcEw7IYg1Q",
        "outputId": "edd47612-ffd6-462b-bb3c-5c9b8c6c2894"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 1, 22, 400)]      0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               686644    \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 1, 22, 400)        910785    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1597429 (6.09 MB)\n",
            "Trainable params: 1597045 (6.09 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vae model\n",
        "history = vae.fit(X_train,X_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_test, X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skf1GHMwYkwj",
        "outputId": "bdd2b97e-4db3-4e8e-940a-71b8e50ab66a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "29/29 [==============================] - 20s 86ms/step - loss: 0.1140 - accuracy: 0.0029 - val_loss: 0.1534 - val_accuracy: 0.0033\n",
            "Epoch 2/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0113 - accuracy: 0.0021 - val_loss: 0.1470 - val_accuracy: 0.0045\n",
            "Epoch 3/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0081 - accuracy: 0.0038 - val_loss: 0.1456 - val_accuracy: 0.0030\n",
            "Epoch 4/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0068 - accuracy: 0.0032 - val_loss: 0.1373 - val_accuracy: 0.0016\n",
            "Epoch 5/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.0038 - val_loss: 0.1278 - val_accuracy: 0.0020\n",
            "Epoch 6/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 0.0035 - val_loss: 0.1229 - val_accuracy: 0.0024\n",
            "Epoch 7/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 0.0038 - val_loss: 0.1135 - val_accuracy: 0.0028\n",
            "Epoch 8/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 0.0045 - val_loss: 0.1101 - val_accuracy: 0.0022\n",
            "Epoch 9/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 0.0040 - val_loss: 0.1000 - val_accuracy: 0.0018\n",
            "Epoch 10/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 0.0038 - val_loss: 0.0930 - val_accuracy: 0.0026\n",
            "Epoch 11/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 0.0038 - val_loss: 0.0852 - val_accuracy: 0.0030\n",
            "Epoch 12/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.0039 - val_loss: 0.0740 - val_accuracy: 0.0031\n",
            "Epoch 13/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 0.0034 - val_loss: 0.0653 - val_accuracy: 0.0026\n",
            "Epoch 14/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 0.0032 - val_loss: 0.0562 - val_accuracy: 0.0026\n",
            "Epoch 15/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 0.0041 - val_loss: 0.0472 - val_accuracy: 0.0031\n",
            "Epoch 16/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 0.0031 - val_loss: 0.0367 - val_accuracy: 0.0033\n",
            "Epoch 17/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.0041 - val_loss: 0.0313 - val_accuracy: 0.0026\n",
            "Epoch 18/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 0.0037 - val_loss: 0.0240 - val_accuracy: 0.0031\n",
            "Epoch 19/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 0.0039 - val_loss: 0.0203 - val_accuracy: 0.0039\n",
            "Epoch 20/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 0.0044 - val_loss: 0.0163 - val_accuracy: 0.0026\n",
            "Epoch 21/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 0.0038 - val_loss: 0.0125 - val_accuracy: 0.0026\n",
            "Epoch 22/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 0.0053 - val_loss: 0.0099 - val_accuracy: 0.0033\n",
            "Epoch 23/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 0.0058 - val_loss: 0.0069 - val_accuracy: 0.0041\n",
            "Epoch 24/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 0.0042 - val_loss: 0.0075 - val_accuracy: 0.0030\n",
            "Epoch 25/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0037 - accuracy: 0.0056 - val_loss: 0.0048 - val_accuracy: 0.0049\n",
            "Epoch 26/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0034 - accuracy: 0.0049 - val_loss: 0.0047 - val_accuracy: 0.0061\n",
            "Epoch 27/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0038 - accuracy: 0.0058 - val_loss: 0.0036 - val_accuracy: 0.0075\n",
            "Epoch 28/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0033 - accuracy: 0.0047 - val_loss: 0.0032 - val_accuracy: 0.0047\n",
            "Epoch 29/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0034 - accuracy: 0.0057 - val_loss: 0.0033 - val_accuracy: 0.0069\n",
            "Epoch 30/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0034 - accuracy: 0.0056 - val_loss: 0.0030 - val_accuracy: 0.0057\n",
            "Epoch 31/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0034 - accuracy: 0.0060 - val_loss: 0.0031 - val_accuracy: 0.0061\n",
            "Epoch 32/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0035 - accuracy: 0.0062 - val_loss: 0.0031 - val_accuracy: 0.0067\n",
            "Epoch 33/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0034 - accuracy: 0.0063 - val_loss: 0.0031 - val_accuracy: 0.0047\n",
            "Epoch 34/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 0.0067 - val_loss: 0.0031 - val_accuracy: 0.0049\n",
            "Epoch 35/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0063 - val_loss: 0.0033 - val_accuracy: 0.0039\n",
            "Epoch 36/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0030 - val_accuracy: 0.0063\n",
            "Epoch 37/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0031 - accuracy: 0.0067 - val_loss: 0.0033 - val_accuracy: 0.0055\n",
            "Epoch 38/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0061 - val_loss: 0.0031 - val_accuracy: 0.0053\n",
            "Epoch 39/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 0.0076 - val_loss: 0.0031 - val_accuracy: 0.0079\n",
            "Epoch 40/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0066 - val_loss: 0.0031 - val_accuracy: 0.0081\n",
            "Epoch 41/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0033 - accuracy: 0.0062 - val_loss: 0.0031 - val_accuracy: 0.0051\n",
            "Epoch 42/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0060 - val_loss: 0.0030 - val_accuracy: 0.0055\n",
            "Epoch 43/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 0.0061 - val_loss: 0.0031 - val_accuracy: 0.0067\n",
            "Epoch 44/1000\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0030 - val_accuracy: 0.0053\n",
            "Epoch 45/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0068 - val_loss: 0.0030 - val_accuracy: 0.0067\n",
            "Epoch 46/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0034 - accuracy: 0.0067 - val_loss: 0.0033 - val_accuracy: 0.0059\n",
            "Epoch 47/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0031 - accuracy: 0.0071 - val_loss: 0.0031 - val_accuracy: 0.0053\n",
            "Epoch 48/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0031 - accuracy: 0.0069 - val_loss: 0.0030 - val_accuracy: 0.0045\n",
            "Epoch 49/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0031 - accuracy: 0.0065 - val_loss: 0.0030 - val_accuracy: 0.0073\n",
            "Epoch 50/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0031 - accuracy: 0.0061 - val_loss: 0.0030 - val_accuracy: 0.0067\n",
            "Epoch 51/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0030 - accuracy: 0.0062 - val_loss: 0.0030 - val_accuracy: 0.0071\n",
            "Epoch 52/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0031 - accuracy: 0.0055 - val_loss: 0.0030 - val_accuracy: 0.0057\n",
            "Epoch 53/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0031 - accuracy: 0.0069 - val_loss: 0.0030 - val_accuracy: 0.0063\n",
            "Epoch 54/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0032 - accuracy: 0.0074 - val_loss: 0.0030 - val_accuracy: 0.0079\n",
            "Epoch 55/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0031 - accuracy: 0.0071 - val_loss: 0.0030 - val_accuracy: 0.0091\n",
            "Epoch 56/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0031 - accuracy: 0.0063 - val_loss: 0.0030 - val_accuracy: 0.0057\n",
            "Epoch 57/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0031 - accuracy: 0.0079 - val_loss: 0.0030 - val_accuracy: 0.0073\n",
            "Epoch 58/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.0071 - val_loss: 0.0030 - val_accuracy: 0.0079\n",
            "Epoch 59/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0031 - accuracy: 0.0067 - val_loss: 0.0029 - val_accuracy: 0.0049\n",
            "Epoch 60/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0030 - accuracy: 0.0063 - val_loss: 0.0030 - val_accuracy: 0.0081\n",
            "Epoch 61/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0031 - accuracy: 0.0063 - val_loss: 0.0030 - val_accuracy: 0.0098\n",
            "Epoch 62/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0070 - val_loss: 0.0030 - val_accuracy: 0.0077\n",
            "Epoch 63/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0068 - val_loss: 0.0030 - val_accuracy: 0.0087\n",
            "Epoch 64/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.0066 - val_loss: 0.0030 - val_accuracy: 0.0091\n",
            "Epoch 65/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0067 - val_loss: 0.0030 - val_accuracy: 0.0071\n",
            "Epoch 66/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.0062 - val_loss: 0.0031 - val_accuracy: 0.0079\n",
            "Epoch 67/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0071 - val_loss: 0.0032 - val_accuracy: 0.0063\n",
            "Epoch 68/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0071 - val_loss: 0.0030 - val_accuracy: 0.0057\n",
            "Epoch 69/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0063 - val_loss: 0.0030 - val_accuracy: 0.0061\n",
            "Epoch 70/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0066 - val_loss: 0.0030 - val_accuracy: 0.0089\n",
            "Epoch 71/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0074 - val_loss: 0.0030 - val_accuracy: 0.0081\n",
            "Epoch 72/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0081 - val_loss: 0.0030 - val_accuracy: 0.0061\n",
            "Epoch 73/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0082 - val_loss: 0.0030 - val_accuracy: 0.0073\n",
            "Epoch 74/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0074 - val_loss: 0.0030 - val_accuracy: 0.0092\n",
            "Epoch 75/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0059 - val_loss: 0.0029 - val_accuracy: 0.0085\n",
            "Epoch 76/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0080 - val_loss: 0.0029 - val_accuracy: 0.0081\n",
            "Epoch 77/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0078 - val_loss: 0.0030 - val_accuracy: 0.0077\n",
            "Epoch 78/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0072 - val_loss: 0.0029 - val_accuracy: 0.0085\n",
            "Epoch 79/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0082 - val_loss: 0.0029 - val_accuracy: 0.0085\n",
            "Epoch 80/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0080 - val_loss: 0.0029 - val_accuracy: 0.0102\n",
            "Epoch 81/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0077 - val_loss: 0.0030 - val_accuracy: 0.0079\n",
            "Epoch 82/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0074 - val_loss: 0.0030 - val_accuracy: 0.0077\n",
            "Epoch 83/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0030 - accuracy: 0.0077 - val_loss: 0.0029 - val_accuracy: 0.0102\n",
            "Epoch 84/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0076 - val_loss: 0.0031 - val_accuracy: 0.0104\n",
            "Epoch 85/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0031 - accuracy: 0.0073 - val_loss: 0.0029 - val_accuracy: 0.0102\n",
            "Epoch 86/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.0075 - val_loss: 0.0030 - val_accuracy: 0.0069\n",
            "Epoch 87/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0030 - accuracy: 0.0068 - val_loss: 0.0029 - val_accuracy: 0.0092\n",
            "Epoch 88/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.0074 - val_loss: 0.0030 - val_accuracy: 0.0067\n",
            "Epoch 89/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.0076 - val_loss: 0.0030 - val_accuracy: 0.0089\n",
            "Epoch 90/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0030 - accuracy: 0.0076 - val_loss: 0.0030 - val_accuracy: 0.0075\n",
            "Epoch 91/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0075 - val_loss: 0.0029 - val_accuracy: 0.0091\n",
            "Epoch 92/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0087 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 93/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0076 - val_loss: 0.0029 - val_accuracy: 0.0089\n",
            "Epoch 94/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0076 - val_loss: 0.0029 - val_accuracy: 0.0081\n",
            "Epoch 95/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.0085 - val_loss: 0.0030 - val_accuracy: 0.0083\n",
            "Epoch 96/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0086 - val_loss: 0.0030 - val_accuracy: 0.0094\n",
            "Epoch 97/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.0082 - val_loss: 0.0031 - val_accuracy: 0.0073\n",
            "Epoch 98/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0086 - val_loss: 0.0029 - val_accuracy: 0.0063\n",
            "Epoch 99/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0078 - val_loss: 0.0029 - val_accuracy: 0.0098\n",
            "Epoch 100/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0080 - val_loss: 0.0030 - val_accuracy: 0.0087\n",
            "Epoch 101/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0085 - val_loss: 0.0029 - val_accuracy: 0.0079\n",
            "Epoch 102/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0080 - val_loss: 0.0029 - val_accuracy: 0.0094\n",
            "Epoch 103/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0087 - val_loss: 0.0029 - val_accuracy: 0.0081\n",
            "Epoch 104/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0077 - val_loss: 0.0030 - val_accuracy: 0.0069\n",
            "Epoch 105/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0085 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 106/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0082 - val_loss: 0.0029 - val_accuracy: 0.0077\n",
            "Epoch 107/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0095 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 108/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0083 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 109/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0099 - val_loss: 0.0029 - val_accuracy: 0.0092\n",
            "Epoch 110/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0097 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 111/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0084 - val_loss: 0.0030 - val_accuracy: 0.0089\n",
            "Epoch 112/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0032 - accuracy: 0.0086 - val_loss: 0.0030 - val_accuracy: 0.0098\n",
            "Epoch 113/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0031 - accuracy: 0.0088 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 114/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0093 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 115/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0030 - accuracy: 0.0092 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 116/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 0.0105 - val_loss: 0.0029 - val_accuracy: 0.0094\n",
            "Epoch 117/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.0099 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 118/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 0.0086 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 119/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0030 - accuracy: 0.0098 - val_loss: 0.0029 - val_accuracy: 0.0098\n",
            "Epoch 120/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 0.0112 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 121/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0085 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 122/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.0107 - val_loss: 0.0029 - val_accuracy: 0.0081\n",
            "Epoch 123/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0108 - val_loss: 0.0029 - val_accuracy: 0.0094\n",
            "Epoch 124/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0108 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 125/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0117 - val_loss: 0.0030 - val_accuracy: 0.0087\n",
            "Epoch 126/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.0097 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 127/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0105 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 128/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0111 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 129/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0105 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 130/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0101 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 131/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.0112 - val_loss: 0.0030 - val_accuracy: 0.0089\n",
            "Epoch 132/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0118 - val_loss: 0.0029 - val_accuracy: 0.0106\n",
            "Epoch 133/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0121 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 134/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0029 - val_accuracy: 0.0110\n",
            "Epoch 135/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0108 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 136/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0114 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 137/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0113 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 138/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0128 - val_loss: 0.0029 - val_accuracy: 0.0102\n",
            "Epoch 139/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0121 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 140/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0115 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 141/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0114 - val_loss: 0.0029 - val_accuracy: 0.0104\n",
            "Epoch 142/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0124 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 143/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 0.0119 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 144/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0114 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 145/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.0123 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 146/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0124 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 147/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 0.0135 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 148/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0029 - accuracy: 0.0136 - val_loss: 0.0029 - val_accuracy: 0.0102\n",
            "Epoch 149/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0132 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 150/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0124 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 151/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0128 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 152/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0132 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 153/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0123 - val_loss: 0.0030 - val_accuracy: 0.0110\n",
            "Epoch 154/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0122 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 155/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0137 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 156/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0144 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 157/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0133 - val_loss: 0.0028 - val_accuracy: 0.0118\n",
            "Epoch 158/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0128 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 159/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0127 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 160/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0135 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 161/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0149 - val_loss: 0.0028 - val_accuracy: 0.0110\n",
            "Epoch 162/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0129 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 163/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0151 - val_loss: 0.0028 - val_accuracy: 0.0114\n",
            "Epoch 164/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0153 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 165/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0148 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 166/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0132 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 167/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0164 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 168/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0146 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 169/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0150 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 170/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0148 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 171/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0161 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 172/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0157 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 173/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0030 - accuracy: 0.0167 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 174/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0157 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 175/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.0146 - val_loss: 0.0030 - val_accuracy: 0.0152\n",
            "Epoch 176/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.0132 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 177/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0158 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 178/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0161 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 179/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0162 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 180/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0163 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 181/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0172 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 182/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0166 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 183/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0180 - val_loss: 0.0028 - val_accuracy: 0.0181\n",
            "Epoch 184/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0029 - accuracy: 0.0177 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 185/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0169 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 186/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 0.0152 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 187/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0173 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 188/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0171 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 189/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0172 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 190/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0159 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 191/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0170 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 192/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0166 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 193/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0176 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 194/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0166 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 195/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0168 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 196/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0180 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 197/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0176 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 198/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0181 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 199/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0170 - val_loss: 0.0028 - val_accuracy: 0.0177\n",
            "Epoch 200/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0183 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 201/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0185 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 202/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0180 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 203/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0189 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 204/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0175 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 205/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.0168 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 206/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0191 - val_loss: 0.0028 - val_accuracy: 0.0163\n",
            "Epoch 207/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0195 - val_loss: 0.0028 - val_accuracy: 0.0177\n",
            "Epoch 208/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0193 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 209/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0193 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 210/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0182 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 211/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0193 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 212/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0187 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 213/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0193 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 214/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0198 - val_loss: 0.0028 - val_accuracy: 0.0169\n",
            "Epoch 215/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0191 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 216/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0202 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 217/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.0208 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 218/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0199 - val_loss: 0.0028 - val_accuracy: 0.0163\n",
            "Epoch 219/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0201 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 220/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0206 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 221/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0209 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 222/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0176 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 223/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0192 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 224/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 225/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0201 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 226/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0192 - val_loss: 0.0029 - val_accuracy: 0.0177\n",
            "Epoch 227/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0028 - val_accuracy: 0.0132\n",
            "Epoch 228/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0209 - val_loss: 0.0028 - val_accuracy: 0.0177\n",
            "Epoch 229/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0203 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 230/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.0215 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 231/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0214 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 232/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 233/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0201 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 234/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0194 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 235/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0029 - accuracy: 0.0206 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 236/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0200 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 237/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0210 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 238/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0216 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 239/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0213 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 240/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0213 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 241/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0229 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 242/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0210 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 243/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0196 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 244/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0208 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 245/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0211 - val_loss: 0.0029 - val_accuracy: 0.0110\n",
            "Epoch 246/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0217 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 247/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0205 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 248/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0218 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 249/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0224 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 250/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0217 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 251/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0220 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 252/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0234 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 253/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0217 - val_loss: 0.0029 - val_accuracy: 0.0177\n",
            "Epoch 254/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0224 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 255/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0201 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 256/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0213 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 257/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0221 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 258/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0234 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 259/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0227 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 260/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0217 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 261/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0208 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 262/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0210 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 263/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0218 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 264/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0215 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 265/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0212 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 266/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0213 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 267/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0213 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 268/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0205 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 269/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0217 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 270/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0222 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 271/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0207 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 272/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0206 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 273/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0219 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 274/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0227 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 275/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 276/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0222 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 277/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0236 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 278/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0221 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 279/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0231 - val_loss: 0.0029 - val_accuracy: 0.0110\n",
            "Epoch 280/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0225 - val_loss: 0.0028 - val_accuracy: 0.0175\n",
            "Epoch 281/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0227 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 282/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0221 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 283/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0218 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 284/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0231 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 285/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0221 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 286/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0230 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 287/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0238 - val_loss: 0.0029 - val_accuracy: 0.0110\n",
            "Epoch 288/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0219 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 289/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0230 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 290/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0232 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 291/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0216 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 292/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0220 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 293/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0244 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 294/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0242 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 295/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0236 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 296/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0203 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 297/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0243 - val_loss: 0.0028 - val_accuracy: 0.0169\n",
            "Epoch 298/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0231 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 299/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0235 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 300/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0237 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 301/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0238 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 302/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 303/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0225 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 304/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 305/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0242 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 306/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0245 - val_loss: 0.0028 - val_accuracy: 0.0163\n",
            "Epoch 307/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 308/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0232 - val_loss: 0.0028 - val_accuracy: 0.0173\n",
            "Epoch 309/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0222 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 310/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0240 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 311/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0252 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 312/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0230 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 313/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0240 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 314/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0241 - val_loss: 0.0028 - val_accuracy: 0.0183\n",
            "Epoch 315/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0237 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 316/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0231 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 317/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0244 - val_loss: 0.0028 - val_accuracy: 0.0187\n",
            "Epoch 318/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0247 - val_loss: 0.0028 - val_accuracy: 0.0173\n",
            "Epoch 319/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0239 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 320/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0248 - val_loss: 0.0029 - val_accuracy: 0.0177\n",
            "Epoch 321/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0233 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 322/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0232 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 323/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0237 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 324/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0253 - val_loss: 0.0028 - val_accuracy: 0.0173\n",
            "Epoch 325/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0246 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 326/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0244 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 327/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0240 - val_loss: 0.0028 - val_accuracy: 0.0171\n",
            "Epoch 328/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0249 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 329/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0250 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 330/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0248 - val_loss: 0.0028 - val_accuracy: 0.0173\n",
            "Epoch 331/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0236 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 332/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0244 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 333/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0247 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 334/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0248 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 335/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0241 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 336/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0260 - val_loss: 0.0028 - val_accuracy: 0.0181\n",
            "Epoch 337/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0262 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 338/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0261 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 339/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0245 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 340/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0261 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 341/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0247 - val_loss: 0.0028 - val_accuracy: 0.0130\n",
            "Epoch 342/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0251 - val_loss: 0.0028 - val_accuracy: 0.0169\n",
            "Epoch 343/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0237 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 344/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0247 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 345/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0252 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 346/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0028 - accuracy: 0.0255 - val_loss: 0.0028 - val_accuracy: 0.0163\n",
            "Epoch 347/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0246 - val_loss: 0.0028 - val_accuracy: 0.0171\n",
            "Epoch 348/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0259 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 349/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0244 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 350/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0253 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 351/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0027 - accuracy: 0.0258 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 352/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0271 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 353/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0251 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 354/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0250 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 355/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0252 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 356/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0252 - val_loss: 0.0028 - val_accuracy: 0.0163\n",
            "Epoch 357/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 358/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0250 - val_loss: 0.0028 - val_accuracy: 0.0175\n",
            "Epoch 359/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0260 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 360/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0260 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 361/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0252 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 362/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0261 - val_loss: 0.0028 - val_accuracy: 0.0181\n",
            "Epoch 363/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0028 - accuracy: 0.0248 - val_loss: 0.0029 - val_accuracy: 0.0179\n",
            "Epoch 364/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 365/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0257 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 366/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0265 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 367/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0267 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 368/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0269 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 369/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0252 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 370/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0253 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 371/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0266 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 372/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0265 - val_loss: 0.0029 - val_accuracy: 0.0187\n",
            "Epoch 373/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0272 - val_loss: 0.0028 - val_accuracy: 0.0134\n",
            "Epoch 374/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0256 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 375/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0260 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 376/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0263 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 377/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0261 - val_loss: 0.0028 - val_accuracy: 0.0136\n",
            "Epoch 378/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0256 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 379/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0028 - accuracy: 0.0267 - val_loss: 0.0028 - val_accuracy: 0.0185\n",
            "Epoch 380/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0274 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 381/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.0254 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 382/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0272 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 383/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0281 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 384/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0262 - val_loss: 0.0028 - val_accuracy: 0.0175\n",
            "Epoch 385/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 386/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0266 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 387/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0265 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 388/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0275 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 389/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0269 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 390/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0249 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 391/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0263 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 392/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0267 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 393/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0265 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 394/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0163\n",
            "Epoch 395/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0261 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 396/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0257 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 397/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0274 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 398/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0296 - val_loss: 0.0028 - val_accuracy: 0.0171\n",
            "Epoch 399/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0265 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 400/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0286 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 401/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0268 - val_loss: 0.0028 - val_accuracy: 0.0175\n",
            "Epoch 402/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0191\n",
            "Epoch 403/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0278 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 404/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0278 - val_loss: 0.0028 - val_accuracy: 0.0169\n",
            "Epoch 405/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0267 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 406/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0274 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 407/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0272 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 408/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0272 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 409/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0270 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 410/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0269 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 411/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0279 - val_loss: 0.0028 - val_accuracy: 0.0171\n",
            "Epoch 412/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0267 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 413/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0274 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 414/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0264 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 415/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0272 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 416/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0286 - val_loss: 0.0028 - val_accuracy: 0.0175\n",
            "Epoch 417/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0293 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 418/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0273 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 419/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 420/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0275 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 421/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0283 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 422/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0280 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 423/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0292 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 424/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0299 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 425/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0287 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 426/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0281 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 427/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0282 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 428/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0287 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 429/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0296 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 430/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0297 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 431/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0302 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 432/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0277 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 433/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0277 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 434/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0283 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 435/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0281 - val_loss: 0.0028 - val_accuracy: 0.0179\n",
            "Epoch 436/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0270 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 437/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0292 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 438/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0272 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 439/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0279 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 440/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0300 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 441/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0027 - accuracy: 0.0281 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 442/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0280 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 443/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0290 - val_loss: 0.0028 - val_accuracy: 0.0179\n",
            "Epoch 444/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0283 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 445/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0280 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 446/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0298 - val_loss: 0.0028 - val_accuracy: 0.0163\n",
            "Epoch 447/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0292 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 448/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0297 - val_loss: 0.0029 - val_accuracy: 0.0185\n",
            "Epoch 449/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0281 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 450/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0284 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 451/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0297 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 452/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0293 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 453/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0305 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 454/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 455/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0277 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 456/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0289 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 457/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0294 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 458/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0292 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 459/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0311 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 460/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0286 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 461/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0284 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 462/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0281 - val_loss: 0.0028 - val_accuracy: 0.0169\n",
            "Epoch 463/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.0298 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 464/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0280 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 465/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0285 - val_loss: 0.0028 - val_accuracy: 0.0138\n",
            "Epoch 466/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0277 - val_loss: 0.0028 - val_accuracy: 0.0124\n",
            "Epoch 467/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0317 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 468/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0309 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 469/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0300 - val_loss: 0.0029 - val_accuracy: 0.0177\n",
            "Epoch 470/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0290 - val_loss: 0.0029 - val_accuracy: 0.0177\n",
            "Epoch 471/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0313 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 472/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0305 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 473/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0303 - val_loss: 0.0029 - val_accuracy: 0.0175\n",
            "Epoch 474/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 475/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0308 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 476/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0299 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 477/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0304 - val_loss: 0.0028 - val_accuracy: 0.0171\n",
            "Epoch 478/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0299 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 479/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0282 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 480/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0301 - val_loss: 0.0028 - val_accuracy: 0.0173\n",
            "Epoch 481/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0324 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 482/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0311 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 483/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0300 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 484/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0307 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 485/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0304 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 486/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0297 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 487/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0311 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 488/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0304 - val_loss: 0.0028 - val_accuracy: 0.0175\n",
            "Epoch 489/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0318 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 490/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0299 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 491/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0292 - val_loss: 0.0028 - val_accuracy: 0.0169\n",
            "Epoch 492/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0302 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 493/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0303 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 494/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0325 - val_loss: 0.0028 - val_accuracy: 0.0163\n",
            "Epoch 495/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0306 - val_loss: 0.0029 - val_accuracy: 0.0193\n",
            "Epoch 496/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.0284 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 497/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0309 - val_loss: 0.0028 - val_accuracy: 0.0167\n",
            "Epoch 498/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0320 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 499/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0316 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 500/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0299 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 501/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0316 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 502/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0307 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 503/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0300 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 504/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0318 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 505/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0308 - val_loss: 0.0028 - val_accuracy: 0.0128\n",
            "Epoch 506/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0126\n",
            "Epoch 507/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0320 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 508/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0309 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 509/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0305 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 510/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 511/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0299 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 512/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0306 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 513/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0300 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 514/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0306 - val_loss: 0.0028 - val_accuracy: 0.0169\n",
            "Epoch 515/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0307 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 516/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0325 - val_loss: 0.0028 - val_accuracy: 0.0148\n",
            "Epoch 517/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0316 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 518/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0320 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 519/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0330 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 520/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0301 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 521/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0314 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 522/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0317 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 523/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0339 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 524/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0310 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 525/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0317 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 526/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0303 - val_loss: 0.0028 - val_accuracy: 0.0140\n",
            "Epoch 527/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0317 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 528/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0312 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 529/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0311 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 530/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0309 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 531/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0318 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 532/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0329 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 533/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0316 - val_loss: 0.0028 - val_accuracy: 0.0122\n",
            "Epoch 534/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0320 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 535/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0311 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 536/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0321 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 537/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0297 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 538/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0339 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 539/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0318 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 540/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0336 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 541/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0307 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 542/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0311 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 543/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0327 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 544/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 0.0325 - val_loss: 0.0028 - val_accuracy: 0.0177\n",
            "Epoch 545/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0331 - val_loss: 0.0028 - val_accuracy: 0.0169\n",
            "Epoch 546/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0322 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 547/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0325 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 548/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0329 - val_loss: 0.0028 - val_accuracy: 0.0152\n",
            "Epoch 549/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0334 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 550/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0318 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 551/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0325 - val_loss: 0.0028 - val_accuracy: 0.0159\n",
            "Epoch 552/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0319 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 553/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0324 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 554/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0314 - val_loss: 0.0028 - val_accuracy: 0.0179\n",
            "Epoch 555/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0316 - val_loss: 0.0028 - val_accuracy: 0.0146\n",
            "Epoch 556/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0320 - val_loss: 0.0028 - val_accuracy: 0.0144\n",
            "Epoch 557/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0336 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 558/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0327 - val_loss: 0.0028 - val_accuracy: 0.0157\n",
            "Epoch 559/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0326 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 560/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 561/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0316 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 562/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0346 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 563/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0342 - val_loss: 0.0028 - val_accuracy: 0.0177\n",
            "Epoch 564/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 0.0315 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 565/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0330 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 566/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0341 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 567/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 568/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0346 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 569/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0346 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 570/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 571/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0331 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 572/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0343 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 573/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0322 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 574/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0349 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 575/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0337 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 576/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0331 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 577/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 0.0337 - val_loss: 0.0028 - val_accuracy: 0.0161\n",
            "Epoch 578/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0349 - val_loss: 0.0028 - val_accuracy: 0.0150\n",
            "Epoch 579/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0324 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 580/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0345 - val_loss: 0.0028 - val_accuracy: 0.0153\n",
            "Epoch 581/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0321 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 582/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0324 - val_loss: 0.0028 - val_accuracy: 0.0155\n",
            "Epoch 583/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 584/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 0.0343 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 585/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 586/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 587/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0334 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 588/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0330 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 589/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0319 - val_loss: 0.0028 - val_accuracy: 0.0165\n",
            "Epoch 590/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0340 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 591/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0335 - val_loss: 0.0029 - val_accuracy: 0.0179\n",
            "Epoch 592/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0331 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 593/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0027 - accuracy: 0.0345 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 594/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0346 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 595/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0337 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 596/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 597/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0351 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 598/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 599/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0343 - val_loss: 0.0028 - val_accuracy: 0.0142\n",
            "Epoch 600/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0330 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 601/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 602/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0349 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 603/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0324 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 604/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0344 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 605/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0333 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 606/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0333 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 607/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0345 - val_loss: 0.0029 - val_accuracy: 0.0185\n",
            "Epoch 608/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0328 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 609/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0326 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 610/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0352 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 611/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0366 - val_loss: 0.0029 - val_accuracy: 0.0175\n",
            "Epoch 612/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0355 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 613/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0363 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 614/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0336 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 615/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0345 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 616/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0356 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 617/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 618/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 619/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0338 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 620/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0361 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 621/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0348 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 622/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0355 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 623/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0026 - accuracy: 0.0336 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 624/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0351 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 625/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0339 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 626/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0351 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 627/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0351 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 628/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0338 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 629/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0336 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 630/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0355 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 631/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0344 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 632/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0346 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 633/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 634/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 635/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0355 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 636/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 637/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0355 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 638/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.0361 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 639/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0349 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 640/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0335 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 641/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 642/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0342 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 643/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 644/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 645/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0371 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 646/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 647/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0356 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 648/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0394 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 649/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0360 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 650/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0026 - accuracy: 0.0360 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 651/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0365 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 652/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0338 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 653/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 654/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0365 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 655/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0332 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 656/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 657/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 658/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 659/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 660/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0359 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 661/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 662/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 663/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0383 - val_loss: 0.0029 - val_accuracy: 0.0175\n",
            "Epoch 664/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 665/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0371 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 666/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0349 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 667/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0363 - val_loss: 0.0029 - val_accuracy: 0.0177\n",
            "Epoch 668/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0349 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 669/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0365 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 670/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0359 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 671/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0352 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 672/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0351 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 673/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0363 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 674/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0347 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 675/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 676/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 677/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 678/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0356 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 679/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0360 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 680/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0352 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 681/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.0356 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 682/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0367 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 683/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0366 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 684/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0353 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 685/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 686/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 687/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 688/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0187\n",
            "Epoch 689/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0163\n",
            "Epoch 690/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 691/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0369 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 692/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0380 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 693/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 694/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 695/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 696/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 697/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0366 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 698/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0354 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 699/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 700/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 701/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0371 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 702/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0386 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 703/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0351 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 704/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 705/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0394 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 706/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0369 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 707/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 708/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 709/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0374 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 710/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 711/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 712/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 713/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0362 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 714/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0337 - val_loss: 0.0029 - val_accuracy: 0.0165\n",
            "Epoch 715/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 716/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0366 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 717/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 718/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0373 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 719/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0380 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 720/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 721/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0358 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 722/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0372 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 723/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 724/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0368 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 725/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0359 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 726/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0370 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 727/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0369 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 728/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 729/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 730/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 731/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 732/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0397 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 733/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0373 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 734/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 735/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0365 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 736/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0375 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 737/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0175\n",
            "Epoch 738/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0370 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 739/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 740/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 741/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0361 - val_loss: 0.0029 - val_accuracy: 0.0169\n",
            "Epoch 742/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0365 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 743/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0380 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 744/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 745/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 746/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0368 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 747/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 748/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 749/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0371 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 750/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0398 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 751/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0387 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 752/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0365 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 753/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0398 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 754/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 755/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0380 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 756/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 757/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0167\n",
            "Epoch 758/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0361 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 759/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0376 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 760/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 761/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 762/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 763/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0384 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 764/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 765/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0387 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 766/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0398 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 767/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 768/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 769/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0403 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 770/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0383 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 771/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0386 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 772/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 773/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 774/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 775/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0380 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 776/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 777/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0381 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 778/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 779/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0382 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 780/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0400 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 781/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 782/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 783/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0384 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 784/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0413 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 785/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0386 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 786/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0383 - val_loss: 0.0029 - val_accuracy: 0.0171\n",
            "Epoch 787/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0379 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 788/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 789/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 790/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0031 - val_accuracy: 0.0102\n",
            "Epoch 791/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0353 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 792/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0377 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 793/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 794/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 795/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 796/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0026 - accuracy: 0.0384 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 797/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 798/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 799/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 800/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0394 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 801/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0410 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 802/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 803/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0394 - val_loss: 0.0029 - val_accuracy: 0.0177\n",
            "Epoch 804/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0378 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 805/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0161\n",
            "Epoch 806/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 807/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0387 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 808/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 809/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 810/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 811/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0407 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 812/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 813/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.0410 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 814/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0390 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 815/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0411 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 816/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0398 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 817/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0415 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 818/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 819/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 820/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0392 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 821/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0406 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 822/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 823/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0397 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 824/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0397 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 825/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 826/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 827/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0400 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 828/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 829/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 830/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 831/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0395 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 832/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 833/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 834/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 835/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0173\n",
            "Epoch 836/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0400 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 837/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0415 - val_loss: 0.0029 - val_accuracy: 0.0110\n",
            "Epoch 838/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 839/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 840/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0424 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 841/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 842/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0409 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 843/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.0357 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 844/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 845/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0380 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 846/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 847/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0389 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 848/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0398 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 849/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0421 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 850/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 851/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0423 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 852/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0400 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 853/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 854/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0416 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 855/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 856/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 857/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0393 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 858/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 859/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0428 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 860/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0413 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 861/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.0415 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 862/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0419 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 863/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 0.0412 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 864/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0402 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 865/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0419 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 866/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0399 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 867/1000\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0159\n",
            "Epoch 868/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 869/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 870/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0415 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 871/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0415 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 872/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0421 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 873/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0406 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 874/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0403 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 875/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0412 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 876/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 877/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0429 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 878/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0423 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 879/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0411 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 880/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0404 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 881/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 882/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0431 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 883/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 884/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0385 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 885/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0412 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 886/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 0.0403 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 887/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0025 - accuracy: 0.0406 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 888/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 889/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 890/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0405 - val_loss: 0.0029 - val_accuracy: 0.0150\n",
            "Epoch 891/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0423 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 892/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0444 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 893/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0025 - accuracy: 0.0425 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 894/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0427 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 895/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 896/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0419 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 897/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0422 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 898/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0412 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 899/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 900/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0441 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 901/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0423 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 902/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0416 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 903/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0418 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 904/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0412 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 905/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0433 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 906/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0425 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 907/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0434 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 908/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0418 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 909/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0423 - val_loss: 0.0029 - val_accuracy: 0.0134\n",
            "Epoch 910/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0422 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 911/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 912/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0434 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 913/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0028 - accuracy: 0.0330 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 914/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0026 - accuracy: 0.0372 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 915/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.0396 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 916/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0408 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 917/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0026 - accuracy: 0.0426 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 918/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 0.0434 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 919/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0025 - accuracy: 0.0432 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 920/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0410 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 921/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 0.0427 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 922/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0432 - val_loss: 0.0029 - val_accuracy: 0.0146\n",
            "Epoch 923/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0432 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 924/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0422 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 925/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0427 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 926/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0430 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 927/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0434 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 928/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0439 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 929/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0435 - val_loss: 0.0029 - val_accuracy: 0.0118\n",
            "Epoch 930/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0435 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 931/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0422 - val_loss: 0.0029 - val_accuracy: 0.0100\n",
            "Epoch 932/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.0411 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 933/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0410 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 934/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0426 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 935/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0411 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 936/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0442 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 937/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0436 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 938/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 939/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 940/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0442 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 941/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0446 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 942/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0445 - val_loss: 0.0029 - val_accuracy: 0.0110\n",
            "Epoch 943/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0431 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 944/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0025 - accuracy: 0.0421 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 945/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0434 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 946/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0025 - accuracy: 0.0436 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 947/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0025 - accuracy: 0.0435 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 948/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 0.0439 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 949/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0418 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 950/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0441 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 951/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0439 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 952/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0443 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 953/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 0.0428 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 954/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.0427 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 955/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0415 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 956/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0422 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 957/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0425 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 958/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0436 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 959/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0426 - val_loss: 0.0029 - val_accuracy: 0.0106\n",
            "Epoch 960/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0439 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 961/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0416 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 962/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 0.0436 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 963/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0441 - val_loss: 0.0029 - val_accuracy: 0.0112\n",
            "Epoch 964/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0442 - val_loss: 0.0029 - val_accuracy: 0.0114\n",
            "Epoch 965/1000\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 0.0388 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 966/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0364 - val_loss: 0.0029 - val_accuracy: 0.0116\n",
            "Epoch 967/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0424 - val_loss: 0.0029 - val_accuracy: 0.0106\n",
            "Epoch 968/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0426 - val_loss: 0.0029 - val_accuracy: 0.0108\n",
            "Epoch 969/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0428 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 970/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0425 - val_loss: 0.0029 - val_accuracy: 0.0148\n",
            "Epoch 971/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0445 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 972/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0438 - val_loss: 0.0029 - val_accuracy: 0.0120\n",
            "Epoch 973/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0438 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 974/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0025 - accuracy: 0.0452 - val_loss: 0.0029 - val_accuracy: 0.0122\n",
            "Epoch 975/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.0025 - accuracy: 0.0433 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 976/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0025 - accuracy: 0.0458 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 977/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0025 - accuracy: 0.0421 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 978/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 0.0025 - accuracy: 0.0458 - val_loss: 0.0029 - val_accuracy: 0.0144\n",
            "Epoch 979/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 0.0025 - accuracy: 0.0455 - val_loss: 0.0029 - val_accuracy: 0.0140\n",
            "Epoch 980/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0025 - accuracy: 0.0433 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 981/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0025 - accuracy: 0.0427 - val_loss: 0.0029 - val_accuracy: 0.0130\n",
            "Epoch 982/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0025 - accuracy: 0.0439 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 983/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0025 - accuracy: 0.0421 - val_loss: 0.0030 - val_accuracy: 0.0116\n",
            "Epoch 984/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 0.0025 - accuracy: 0.0441 - val_loss: 0.0029 - val_accuracy: 0.0128\n",
            "Epoch 985/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 0.0437 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 986/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0446 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 987/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0452 - val_loss: 0.0029 - val_accuracy: 0.0138\n",
            "Epoch 988/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0417 - val_loss: 0.0029 - val_accuracy: 0.0157\n",
            "Epoch 989/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0451 - val_loss: 0.0029 - val_accuracy: 0.0126\n",
            "Epoch 990/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0422 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 991/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0436 - val_loss: 0.0029 - val_accuracy: 0.0153\n",
            "Epoch 992/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.0391 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 993/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 0.0374 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 994/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0414 - val_loss: 0.0029 - val_accuracy: 0.0142\n",
            "Epoch 995/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0420 - val_loss: 0.0029 - val_accuracy: 0.0124\n",
            "Epoch 996/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0427 - val_loss: 0.0029 - val_accuracy: 0.0152\n",
            "Epoch 997/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0438 - val_loss: 0.0029 - val_accuracy: 0.0132\n",
            "Epoch 998/1000\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.0025 - accuracy: 0.0448 - val_loss: 0.0029 - val_accuracy: 0.0155\n",
            "Epoch 999/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0445 - val_loss: 0.0029 - val_accuracy: 0.0136\n",
            "Epoch 1000/1000\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0025 - accuracy: 0.0446 - val_loss: 0.0029 - val_accuracy: 0.0140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caminho = '/content/drive/MyDrive/Unicamp/23.2/DL para sintese de sinais/Projetos computacionais/A1 - Projeto Final/Códigos/'\n",
        "# Salvar o modelo\n",
        "vae.save(caminho+'modelo_vae')\n",
        "# Salvar os pesos\n",
        "vae.save_weights(caminho+'pesos_vae')"
      ],
      "metadata": {
        "id": "QtYtwvIuj541"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss curves\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('loss curves')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "sFw-jnbiYm7A",
        "outputId": "6a2bd454-d561-42b5-b3d7-703cd755b60b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss curves\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('val curves')\n",
        "plt.ylabel('Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "bhMzr79x5tF8",
        "outputId": "41662aba-b084-42e5-c4ee-1336d75e5d1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "# Carregar o modelo\n",
        "vae_carregado = load_model(caminho+'modelo_vae')\n",
        "vae_carregado.summary()\n",
        "\n",
        "# Avialiar o modelo carregado\n",
        "loss, acc = vae_carregado.evaluate(X_test,verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "print(vae_carregado.predict(X_test).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSomo41pkUMd",
        "outputId": "276b4a8b-d1c3-4fff-cac5-07cc3c4b3f83"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 1, 22, 400)]      0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               686644    \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 1, 22, 400)        910785    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1597429 (6.09 MB)\n",
            "Trainable params: 1597045 (6.09 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n",
            "8/8 - 0s - loss: 0.0000e+00 - accuracy: 0.0000e+00 - 317ms/epoch - 40ms/step\n",
            "Restored model, accuracy:  0.00%\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "(231, 1, 22, 400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Espaço latente"
      ],
      "metadata": {
        "id": "jAsNIvdbhtcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D plot of the classes in latent space\n",
        "latent_space, _, _ = encoder.predict(X_test,batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grkd64h6Ypyb",
        "outputId": "e4b39716-21a6-41ab-d24f-4a9a54fa2adb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar K-means\n",
        "num_clusters = 4  # Número de clusters igual ao número de labels\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "cluster_labels = kmeans.fit_predict(latent_space)\n",
        "\n",
        "reducer = umap.UMAP(n_neighbors=10,min_dist=0.5) #50 e 0.5\n",
        "embedding = reducer.fit_transform(latent_space)\n",
        "\n",
        "# Visualizar UMAP\n",
        "import plotly.express as px\n",
        "proj = pd.DataFrame(embedding)\n",
        "proj.columns = [\"componente_1\", \"componente_2\"]\n",
        "proj[\"labels\"] = y_train[:231]\n",
        "fig = px.scatter(proj, x='componente_1', y='componente_2', color = cluster_labels, width=800)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "PV5HjGK1bbY7",
        "outputId": "9d928068-b65b-47b4-b370-5deb99d71de1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b7168394-71ea-4676-b391-f737d6082026\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b7168394-71ea-4676-b391-f737d6082026\")) {                    Plotly.newPlot(                        \"b7168394-71ea-4676-b391-f737d6082026\",                        [{\"hovertemplate\":\"componente_1=%{x}\\u003cbr\\u003ecomponente_2=%{y}\\u003cbr\\u003ecolor=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,3,2,3,0,2,1,1,1,2,2,2,2,1,2,2,3,0,2,0,0,2,2,0,0,2,0,2,2,3,2,0,3,2,2,0,2,1,2,2,0,0,0,1,2,2,0,0,0,2,1,1,1,2,0,3,0,0,2,1,2,0,1,3,1,2,3,0,0,2,1,2,1,2,2,0,2,2,0,0,0,0,1,0,3,0,0,1,0,2,0,0,1,2,0,2,2,1,0,2,0,0,2,1,0,1,1,1,2,2,0,2,1,0,0,2,0,0,2,2,2,1,2,1,0,1,0,0,0,2,1,0,2,3,1,1,0,2,1,0,0,0,0,0,1,1,2,0,0,1,0,0,3,2,3,1,0,2,0,0,0,0,1,2,0,1,1,3,0,2,3,0,0,1,2,0,0,1,3,1,0,3,2,1,3,0,1,2,2,0,2,0,2,3,0,2,3,2,0,1,2,1,0,0,2,0,2,1,2,1,1,0,0,0,2,1,2,0,0,2,0,2,3,2,3,0,2,0,0,0,1],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[2.658761739730835,4.439105033874512,10.992912292480469,2.854576349258423,3.10353422164917,10.517030715942383,8.198612213134766,7.849628448486328,9.552360534667969,9.236563682556152,9.141524314880371,9.893377304077148,8.494722366333008,10.327043533325195,11.701027870178223,12.206171989440918,1.4751454591751099,4.786160945892334,13.212457656860352,4.188206195831299,4.715691566467285,11.729703903198242,12.52658748626709,7.010929107666016,1.1905039548873901,11.000897407531738,5.925012111663818,8.77808666229248,10.764609336853027,2.8934576511383057,12.360382080078125,3.0064399242401123,2.9027037620544434,11.248069763183594,13.79423713684082,0.8957841992378235,12.444793701171875,8.425148963928223,12.064050674438477,12.612432479858398,4.1062092781066895,7.471405506134033,3.7808432579040527,7.200687408447266,13.526930809020996,10.308265686035156,2.8741610050201416,0.8741512298583984,7.29955530166626,10.5180025100708,8.707915306091309,7.971373081207275,11.077722549438477,12.897353172302246,2.441216230392456,2.3561925888061523,8.131239891052246,7.651423454284668,9.870870590209961,7.528517246246338,9.727408409118652,8.707902908325195,8.936786651611328,4.9319233894348145,6.899187088012695,12.922627449035645,1.5437308549880981,2.388627529144287,6.629701137542725,10.128116607666016,9.048587799072266,11.617942810058594,9.978313446044922,10.871484756469727,12.76538372039795,5.292938232421875,8.734467506408691,9.912373542785645,4.888026237487793,2.978773593902588,7.099113464355469,2.076268196105957,7.354184627532959,6.484129428863525,2.767655372619629,6.704066276550293,6.809354305267334,7.842859268188477,3.533449649810791,8.515700340270996,2.7241570949554443,5.630993843078613,8.911596298217773,12.018439292907715,6.0309343338012695,9.231928825378418,9.581049919128418,9.304716110229492,1.5630934238433838,12.468371391296387,6.516271114349365,6.465770721435547,12.726083755493164,9.03394603729248,3.589503288269043,9.534666061401367,6.281581878662109,9.873419761657715,14.071812629699707,12.252422332763672,7.473442077636719,13.476816177368164,8.46860408782959,2.0128204822540283,2.6206657886505127,13.616560935974121,5.724008560180664,7.811710357666016,13.862732887268066,13.825271606445312,11.33456039428711,7.37563943862915,11.697457313537598,9.375046730041504,5.162243366241455,9.378667831420898,2.816213369369507,6.308180332183838,1.7888067960739136,11.317604064941406,8.651887893676758,3.039243221282959,11.356406211853027,2.9028749465942383,7.606287956237793,8.288872718811035,2.5953776836395264,11.98090648651123,8.03307819366455,5.7245612144470215,5.234779357910156,7.8735175132751465,2.8161890506744385,5.546177387237549,8.738204956054688,9.443230628967285,9.105082511901855,4.093255043029785,2.79577898979187,9.064152717590332,3.439676284790039,2.793250322341919,3.7911322116851807,11.375240325927734,1.2128331661224365,8.65601921081543,8.085297584533691,9.096177101135254,3.7619411945343018,3.045914649963379,3.8535385131835938,4.170253276824951,7.123116970062256,11.836115837097168,3.6690385341644287,9.183053016662598,6.82283353805542,2.553802013397217,4.557504653930664,12.388779640197754,2.7150564193725586,6.376165390014648,1.5055180788040161,8.520764350891113,10.405001640319824,2.551772117614746,3.888274669647217,9.115318298339844,2.6063551902770996,6.179959774017334,5.613631248474121,2.9171102046966553,9.93920612335205,8.498514175415039,3.101961135864258,7.572669506072998,8.834856033325195,10.728751182556152,9.475409507751465,8.037362098693848,13.191267967224121,4.742105007171631,13.019224166870117,2.4307613372802734,6.101714611053467,10.626105308532715,1.8699543476104736,12.410462379455566,5.99395227432251,10.606245040893555,9.574572563171387,8.431288719177246,5.71251106262207,2.1941168308258057,12.353621482849121,5.880456924438477,13.044831275939941,8.959701538085938,10.133371353149414,9.259626388549805,8.628738403320312,4.1858744621276855,0.9252787232398987,1.2148092985153198,12.208537101745605,6.074631690979004,10.814239501953125,1.8921927213668823,6.319118022918701,12.930587768554688,4.439336776733398,12.63102912902832,3.8224751949310303,10.663142204284668,2.7417049407958984,7.233735084533691,8.706306457519531,5.163336277008057,4.147207260131836,7.614344596862793,9.520524024963379],\"xaxis\":\"x\",\"y\":[2.7247562408447266,4.754218578338623,0.7443459033966064,5.391982555389404,0.32883408665657043,1.712723970413208,6.224598407745361,5.047379016876221,7.718677997589111,-1.0779283046722412,2.168928384780884,-1.0633970499038696,2.7907779216766357,5.0352983474731445,1.4710148572921753,3.531806707382202,3.5433359146118164,3.330219268798828,3.006227731704712,1.808375597000122,-1.5331859588623047,2.349663019180298,-0.09962564706802368,-0.6477677822113037,2.1001548767089844,4.765629768371582,3.3851418495178223,-0.24883641302585602,1.2564609050750732,5.8209123611450195,0.19289550185203552,-1.3335480690002441,5.63380241394043,2.1581177711486816,2.888444185256958,2.2114996910095215,0.4870539605617523,5.599248886108398,2.9621379375457764,4.127950668334961,-1.4979088306427002,0.9902240633964539,-1.5608099699020386,5.23366641998291,3.6937007904052734,-0.8764100670814514,0.70619797706604,1.6877731084823608,-0.7375892400741577,4.427899360656738,4.813691139221191,7.439446449279785,5.843085765838623,-0.5213130712509155,3.276175022125244,4.842483997344971,-0.48744338750839233,2.4132802486419678,1.116315245628357,6.060811996459961,-0.20556572079658508,-1.1293635368347168,4.419477462768555,4.972387313842773,5.202886581420898,-0.14857636392116547,3.36395263671875,2.3567678928375244,-0.8723843097686768,1.1255279779434204,7.276503086090088,-1.0649118423461914,6.284201145172119,-0.9378714561462402,4.55571174621582,-1.455105185508728,3.0963222980499268,0.5179981589317322,1.3287694454193115,0.02847243659198284,3.0984063148498535,1.8399938344955444,4.36909818649292,-1.2771155834197998,5.280569553375244,-1.2686097621917725,0.9248446226119995,5.418461322784424,-1.5765348672866821,2.512941598892212,2.311052083969116,4.311745643615723,8.277016639709473,5.2142229080200195,-1.0458017587661743,2.0286529064178467,0.3433515727519989,4.059835910797119,1.1500486135482788,3.197270631790161,3.6715691089630127,3.423654079437256,3.281738758087158,4.336105823516846,1.0730736255645752,4.655004501342773,5.462061405181885,5.290378570556641,3.0893075466156006,2.546884298324585,-1.2341500520706177,4.335948467254639,6.624954700469971,1.7302836179733276,-0.21430067718029022,3.161346197128296,2.9656577110290527,0.7886597514152527,3.598837375640869,3.350804090499878,-1.2667450904846191,6.874611854553223,0.7844351530075073,8.159340858459473,3.684025287628174,7.787473678588867,-0.8137953281402588,3.6223583221435547,1.4012179374694824,-1.0840823650360107,6.279791355133057,-0.5559777617454529,-1.3143336772918701,4.818881988525391,7.118494987487793,7.139436721801758,0.5096042156219482,3.282524585723877,3.075312614440918,4.06109619140625,-1.0719841718673706,1.2432849407196045,-0.5252320766448975,1.7810146808624268,5.424732208251953,7.078203201293945,-0.6778278946876526,2.1201071739196777,1.558825135231018,8.39681625366211,1.6003044843673706,3.4720451831817627,4.668034076690674,1.292738437652588,3.000302791595459,5.004925727844238,-0.08109650760889053,3.0939576625823975,-1.3624465465545654,-1.3013039827346802,2.001823663711548,0.4117697775363922,4.849268913269043,0.4036407470703125,1.920397400856018,4.051905155181885,5.643895626068115,5.477440357208252,-1.1489319801330566,-0.637539803981781,3.7563891410827637,2.91528582572937,1.573430061340332,7.566929817199707,0.5956025123596191,-0.8125089406967163,2.537217140197754,6.790024280548096,5.186544418334961,5.313736438751221,3.6448516845703125,4.284496307373047,0.8392350673675537,4.094381809234619,4.048956394195557,-1.0615853071212769,7.565916538238525,0.9835078716278076,-0.9292960166931152,1.3870140314102173,4.1481428146362305,3.8089165687561035,0.3082159459590912,4.2836012840271,3.096067428588867,4.811600208282471,4.0685930252075195,4.299535274505615,-1.2712429761886597,5.270824909210205,0.6225974559783936,7.695385932922363,2.429757595062256,1.0607178211212158,4.832461833953857,-1.3733386993408203,-0.07679735869169235,5.940765857696533,3.896678924560547,8.249262809753418,7.0183820724487305,-0.002778124762699008,1.8083655834197998,2.160038709640503,2.7789478302001953,5.083608627319336,4.284893989562988,1.0929805040359497,-1.3684109449386597,4.6619954109191895,0.9148368239402771,0.054881393909454346,4.7514214515686035,4.58620023727417,4.665102005004883,1.1018115282058716,2.2782046794891357,3.7123405933380127,1.298169493675232,1.3747437000274658,6.625020980834961],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"componente_1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"componente_2\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"color\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b7168394-71ea-4676-b391-f737d6082026');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}